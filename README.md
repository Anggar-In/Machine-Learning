<h1 align="center">
<img align="center" src="https://github.com/user-attachments/assets/8a6f2ad2-2fc6-4bd4-ba68-c6674edd655b" alt="Logo Anggarin" width="500" style="border-radius: 50%;"></img>
<br>
<br>
ANGGAR.IN MACHINE LEARNING DOCUMENTATION
</h1>
<div align="center">

![Contributors](https://img.shields.io/github/contributors/Anggar-In/Machine-Learning?color=blue)
![Commit Activity](https://img.shields.io/github/commit-activity/m/Anggar-In/Machine-Learning?color=blue)
![Last Commit](https://img.shields.io/github/last-commit/Anggar-In/Machine-Learning?color=red)
![Forks](https://img.shields.io/github/forks/Anggar-In/Machine-Learning?style=flat-square)

</div>

# Team Profile

### Team ID : C242-PS048

### These Are Our Team Members in the Machine learning Division:

* (ML) M312B4KY2530 - Mochammad Dhiya Ulhaq - Universitas Sebelas Maret
* (ML) M312B4KY2631 - Muhamad Faqih Zacky - Universitas Sebelas Maret
* (ML) M312B4KX3214 - Nadya Putri Uswatun Hasanah - Universitas Sebelas Maret

### Roles

* Stock Recommendation (Financial Freedom Calculator) - Mochammad Dhiya Ulhaq (M312B4KY2530) & Nadya Putri Uswatun Hasanah (M312B4KX3214)
* Stock Prediction (Financial Freedom Calculator) - Mochammad Dhiya Ulhaq (M312B4KY2530) & Nadya Putri Uswatun Hasanah (M312B4KX3214)
* Receipt OCR (Income and Expense Tracking) - Muhamad Faqih Zacky (M312B4KY2631)
* Audio Recognition (Income and Expense Tracking) - Muhamad Faqih Zacky (M312B4KY2631)

# Anggar.In Machine Learing Project Explanation
This Machine Learning project is our final project for Google Bangkit Academy 2024 Batch 2.

**Project Background:**

Financial stability is crucial for personal and societal well-being, yet many Indonesians face challenges in achieving it. Data from BPS and a 2023 DBS survey indicate a large portion of household income is spent on non-essential items without proper planning. This issue is compounded by low financial literacy, leading to unnecessary spending and limiting the ability to save. If left unaddressed, these problems may prolong financial instability and negatively affect the quality of life in Indonesia.

To tackle this issue, our team developed Anggar.In, a comprehensive financial management solution. The app helps users track income and expenses through manual input, receipt scanning, and voice commands, offering a clear view of spending patterns. Its personalized budgeting feature aids in managing spending limits, while savings goal planning supports consistent savings. Anggar.In also provides financial analysis tools, presenting spending trends and insights to help users become more aware of their finances. The investment recommendation system can also guide users towards financial freedom.

Leveraging machine learning, cloud computing, and mobile technology, Anggar.In aims to boost financial awareness, foster sustainable habits, and support informed decision-making, helping Indonesians navigate economic challenges and build long-term financial resilience.


**Mobile Development:**
[Anggar.In Mobile Developments Repository](https://github.com/Anggar-In/Mobile-Development)

**Cloud Computing:**
[Anggar.In Cloud Computing Repository](https://github.com/Anggar-In/Cloud-Computing)

**Machine Learning:** 

In the Machine Learning path, we developed several features, starting with our MVP stock prediction and recommendation models for a financial freedom calculator. These models utilize TensorFlow, are saved using TensorFlow.js for web deployment, preprocess data using Min-Max Scaler for normalization, and apply time series forecasting for stock price prediction alongside linear regression for stock recommendations. Beyond the MVP, we also building supplementary features beyond the MVP, such as Receipt OCR and Audio Recognition. The Receipt OCR leverages the Pytesseract library for extracting text from images, while the Audio Recognition feature utilizes the WebSpeech API. Both systems are tuned with preprocessing techniques for image or audio and use regex for data extraction. This feature is useful for automating expense and income tracking.
