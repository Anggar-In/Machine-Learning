{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-30 03:47:34.982813: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-30 03:47:34.985712: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-11-30 03:47:34.994972: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732913255.011154  301756 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732913255.015307  301756 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-30 03:47:35.033431: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "file_path = '../trainingDataset/company_information.csv'  # Ganti dengan path file Anda\n",
    "data = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bersihkan data numerik\n",
    "numerical_features = [\n",
    "    'Revenue (B)', 'Gross Profit (B)', 'Net Income (B)',\n",
    "    'Market Cap (B)', 'Annual EPS', 'Return on Equity (%)',\n",
    "    '1 Year Price Returns (%)', '3 Year Price Returns (%)',\n",
    "    '5 Year Price Returns (%)', 'Dividend Yield (%)', 'Payout Ratio (%)'\n",
    "]\n",
    "for col in numerical_features:\n",
    "    data[col] = data[col].replace({',': '', '%': ''}, regex=True).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding untuk kolom 'Sector'\n",
    "sector_encoded = pd.get_dummies(data['Sector'], prefix='Sector')\n",
    "\n",
    "# Gabungkan fitur numerik yang relevan\n",
    "features = pd.concat([sector_encoded, data[numerical_features]], axis=1)\n",
    "\n",
    "# Normalisasi data\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Simpan nama saham untuk referensi\n",
    "stocks = data['Kode Saham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732913257.189314  301756 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# Input layer\n",
    "input_stock = tf.keras.layers.Input(shape=(features_scaled.shape[1],), name=\"stock_features\")\n",
    "\n",
    "# Encoder: Mengubah ke 32 dimensi\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(input_stock)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "embedding = tf.keras.layers.Dense(32, activation='relu', name=\"embedding\")(x)\n",
    "\n",
    "# Decoder: Mengembalikan ke dimensi asli\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(embedding)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "output_reconstructed = tf.keras.layers.Dense(features_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "# Model\n",
    "model = tf.keras.Model(inputs=input_stock, outputs=output_reconstructed)\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fe70c1b4100>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Latih model\n",
    "model.fit(features_scaled, features_scaled, epochs=100, batch_size=2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
     ]
    }
   ],
   "source": [
    "# Ekstrak embedding\n",
    "encoder = tf.keras.Model(inputs=input_stock, outputs=embedding)\n",
    "embeddings = encoder.predict(features_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hitung kemiripan kosinus\n",
    "similarity_matrix = cosine_similarity(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi rekomendasi\n",
    "def recommend(stock_name, top_n=3):\n",
    "    idx = stocks[stocks == stock_name].index[0]\n",
    "    \n",
    "    # Ambil skor kemiripan untuk saham tersebut\n",
    "    similarity_scores = similarity_matrix[idx]\n",
    "    \n",
    "    # Urutkan berdasarkan skor (kecuali saham itu sendiri)\n",
    "    similar_indices = similarity_scores.argsort()[::-1][1:top_n+1]\n",
    "    similar_stocks = stocks.iloc[similar_indices]\n",
    "    similar_scores = similarity_scores[similar_indices]\n",
    "    \n",
    "    # Gabungkan hasil (nama saham dan skor)\n",
    "    recommendations = list(zip(similar_stocks, similar_scores))\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ADMF', np.float32(0.8187435)), ('ABMM', np.float32(0.7905521)), ('ACES', np.float32(0.76197934))]\n"
     ]
    }
   ],
   "source": [
    "# Contoh penggunaan\n",
    "result = recommend('AALI', top_n=3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: ../trainingModel/stock_recommendation_model.h5\n"
     ]
    }
   ],
   "source": [
    "# Buat folder jika belum ada\n",
    "folder_name = \"../trainingModel\"\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "\n",
    "# Path lengkap untuk menyimpan model\n",
    "model_path = os.path.join(folder_name, \"stock_recommendation_model.h5\")\n",
    "\n",
    "# Simpan model ke folder\n",
    "model.save(model_path)\n",
    "print(f\"Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n"
     ]
    }
   ],
   "source": [
    "# Memuat kembali model dari folder\n",
    "loaded_model = tf.keras.models.load_model(model_path)\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "# Ekstrak encoder dari model yang dimuat\n",
    "loaded_encoder = tf.keras.Model(inputs=loaded_model.input, outputs=loaded_model.get_layer(\"embedding\").output)\n",
    "\n",
    "# Mendapatkan kembali embedding menggunakan encoder yang dimuat\n",
    "loaded_embeddings = loaded_encoder.predict(features_scaled)\n",
    "\n",
    "# Hitung ulang kemiripan kosinus dengan model yang dimuat\n",
    "loaded_similarity_matrix = cosine_similarity(loaded_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungsi rekomendasi menggunakan model yang dimuat\n",
    "def recommend_from_loaded_model(stock_name, top_n=3):\n",
    "    idx = stocks[stocks == stock_name].index[0]\n",
    "    \n",
    "    # Ambil skor kemiripan untuk saham tersebut\n",
    "    similarity_scores = loaded_similarity_matrix[idx]\n",
    "    \n",
    "    # Urutkan berdasarkan skor (kecuali saham itu sendiri)\n",
    "    similar_indices = similarity_scores.argsort()[::-1][1:top_n+1]\n",
    "    similar_stocks = stocks.iloc[similar_indices]\n",
    "    similar_scores = similarity_scores[similar_indices]\n",
    "    \n",
    "    # Gabungkan hasil (nama saham dan skor)\n",
    "    recommendations = list(zip(similar_stocks, similar_scores))\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ADMF', np.float32(0.8187435)), ('ABMM', np.float32(0.7905521)), ('ACES', np.float32(0.76197934))]\n"
     ]
    }
   ],
   "source": [
    "# Contoh penggunaan\n",
    "result = recommend_from_loaded_model('AALI', top_n=3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
      "Mean Absolute Error (MAE) of the model: 0.0085\n"
     ]
    }
   ],
   "source": [
    "# Mendapatkan prediksi rekonstruksi dari model\n",
    "predicted_features = loaded_model.predict(features_scaled)\n",
    "\n",
    "# Menghitung MAE antara input asli dan rekonstruksi\n",
    "mae = mean_absolute_error(features_scaled, predicted_features)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE) of the model: {mae:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
